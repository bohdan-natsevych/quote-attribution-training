{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BookNLP Maximum Performance Quote Attribution (Unified)\n",
    "\n",
    "**Goal**: Train the max-performance quote attribution model (80‚Äì90% accuracy) in either Kaggle or Colab via one RUN_ENV-aware notebook.\n",
    "\n",
    "**Features**\n",
    "- DeBERTa-v3-large with quote/candidate masks + [QUOTE], [ALTQUOTE], [PAR]\n",
    "- Candidate-level softmax with label smoothing; optional R-Drop; optional temperature scaling\n",
    "- Optional multi-source loading + genre-balanced sampler; PDNC fallback; configurable hard negatives\n",
    "- Curriculum sampler + light augmentation; gradient checkpointing + FP16\n",
    "- Auto checkpoint/resume (model/optimizer/scheduler/best_acc) with cadence set by RUN_ENV; bucketed eval + placeholder postprocess hook\n",
    "\n",
    "**Requirements**\n",
    "- Kaggle: T4 x2 accelerator; storage under `/kaggle/working`\n",
    "- Colab: T4 GPU; storage in Drive at `/content/drive`\n",
    "\n",
    "**Quick start**\n",
    "1) Set `RUN_ENV = \"kaggle\"` or `\"colab\"` in the next cell (default: kaggle).\n",
    "2) Kaggle: no Drive mount; repo/output in `/kaggle/working`; multi-GPU via `accelerate`; checkpoints/evals every 500 steps; auto-resume from latest `checkpoint_*.pt`.\n",
    "3) Colab: mounts Drive to `/content/drive`; repo in `/content`; outputs in Drive; single-GPU (no DDP) with gradient accumulation; checkpoints/evals every 300 steps; auto-resume from latest `checkpoint_*.pt`.\n",
    "4) Run all cells‚Äîdata is cloned automatically from the repo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN_ENV toggle\n",
    "Set `RUN_ENV = \"kaggle\"` or `\"colab\"` in the next cell (default: kaggle). Paths, checkpoint cadence, and mounts adjust automatically. Kaggle uses multi-GPU via `accelerate` (no Drive mount); Colab mounts Drive, runs single-GPU with gradient accumulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "PyTorch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPUs: 2\n",
      "  GPU 0: Tesla T4\n",
      "  GPU 1: Tesla T4\n",
      "Data repo root: /kaggle/working/speaker-attribution-acl2023\n",
      "\n",
      "üì• Cloning training code repository...\n",
      "Cloning into '/kaggle/working/quote-attribution-training'...\n",
      "remote: Enumerating objects: 60, done.\u001b[K\n",
      "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 60 (delta 26), reused 51 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (60/60), 100.37 KiB | 3.72 MiB/s, done.\n",
      "Resolving deltas: 100% (26/26), done.\n",
      "‚úÖ Added /kaggle/working/quote-attribution-training to Python path\n",
      "Data root: /kaggle/working/speaker-attribution-acl2023/data\n",
      "Output root: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os, sys, torch\n",
    "\n",
    "# CURSOR: Toggle once; everything else keys off this value\n",
    "RUN_ENV = os.environ.get(\"RUN_ENV\", \"kaggle\").strip().lower()\n",
    "ENV_CFG = {\n",
    "    \"kaggle\": {\n",
    "        \"base_dir\": \"/kaggle/working\",\n",
    "        \"repo_dir\": \"/kaggle/working/speaker-attribution-acl2023\",\n",
    "        \"training_repo_dir\": \"/kaggle/working/quote-attribution-training\",\n",
    "        \"output_root\": \"/kaggle/working\",\n",
    "        \"checkpoint_every\": 500,\n",
    "        \"eval_every\": 500,\n",
    "        \"grad_accum\": 4,\n",
    "        \"mount_drive\": False,\n",
    "    },\n",
    "    \"colab\": {\n",
    "        \"base_dir\": \"/content/drive/MyDrive/quote_attribution\",\n",
    "        \"repo_dir\": \"/content/speaker-attribution-acl2023\",\n",
    "        \"training_repo_dir\": \"/content/quote-attribution-training\",\n",
    "        \"output_root\": \"/content/drive/MyDrive/quote_attribution\",\n",
    "        \"checkpoint_every\": 300,\n",
    "        \"eval_every\": 300,\n",
    "        \"grad_accum\": 16,\n",
    "        \"mount_drive\": True,\n",
    "    },\n",
    "}\n",
    "assert RUN_ENV in ENV_CFG, f\"Unsupported RUN_ENV: {RUN_ENV}\"\n",
    "ENV = ENV_CFG[RUN_ENV]\n",
    "\n",
    "if ENV[\"mount_drive\"]:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.makedirs(ENV[\"base_dir\"], exist_ok=True)\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU not available; enable a GPU runtime.\")\n",
    "\n",
    "# Data root (datasets auto-downloaded later based on CONFIG['datasets'])\n",
    "REPO_DIR = ENV[\"repo_dir\"]\n",
    "os.makedirs(REPO_DIR, exist_ok=True)\n",
    "print(f\"Data repo root: {REPO_DIR}\")\n",
    "\n",
    "# Clone training code repository\n",
    "TRAINING_REPO_DIR = ENV[\"training_repo_dir\"]\n",
    "if not os.path.exists(TRAINING_REPO_DIR):\n",
    "    print(\"\\nüì• Cloning training code repository...\")\n",
    "    !git clone https://github.com/bohdan-natsevych/quote-attribution-training.git {TRAINING_REPO_DIR}\n",
    "else:\n",
    "    print(f\"‚úÖ Training repository present at {TRAINING_REPO_DIR}\")\n",
    "\n",
    "# Add training repo to Python path for imports\n",
    "if TRAINING_REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, TRAINING_REPO_DIR)\n",
    "    print(f\"‚úÖ Added {TRAINING_REPO_DIR} to Python path\")\n",
    "\n",
    "DATA_ROOT = f\"{REPO_DIR}/data\"\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "BASE_DIR = ENV[\"base_dir\"]\n",
    "OUTPUT_ROOT = ENV[\"output_root\"]\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "print(f\"Output root: {OUTPUT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers>=4.30.0 accelerate>=0.20.0 datasets scikit-learn tqdm nlpaug nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: Target 1: DeBERTa-large + Augmentation\n",
      "Target accuracy: 85%\n",
      "Datasets: ['pdnc']\n",
      "Output dir: /kaggle/working/target_1\n",
      "RUN_ENV: kaggle | checkpoint_every=500 | grad_accum=4\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# CURSOR: Import to get available datasets\n",
    "import sys\n",
    "from enum import Enum\n",
    "if TRAINING_REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, TRAINING_REPO_DIR)\n",
    "\n",
    "from data.multi_source_data import MultiSourceDataLoader\n",
    "\n",
    "# Define Dataset enum from available datasets\n",
    "class Dataset(str, Enum):\n",
    "    \"\"\"Available datasets for quote attribution training.\"\"\"\n",
    "    PDNC = \"pdnc\"\n",
    "    LITBANK = \"litbank\"\n",
    "    DIRECTQUOTE = \"directquote\"\n",
    "    # CURSOR: QUOTEBANK = \"quotebank\"\n",
    "    \n",
    "    @classmethod\n",
    "    def get_all(cls):\n",
    "        \"\"\"Get all dataset values.\"\"\"\n",
    "        return [d.value for d in cls]\n",
    "    \n",
    "    @classmethod\n",
    "    def validate(cls, datasets: list):\n",
    "        \"\"\"Validate that all datasets are in the enum.\"\"\"\n",
    "        valid = cls.get_all()\n",
    "        for ds in datasets:\n",
    "            if ds not in valid:\n",
    "                raise ValueError(f\"Invalid dataset '{ds}'. Must be one of: {valid}\")\n",
    "        return True\n",
    "\n",
    "TARGET_LEVEL = 1  # 1=PDNC, 2=multi-source, 3=ensemble placeholder\n",
    "\n",
    "# CURSOR: For best generalization on unknown/new books, train all 5 folds\n",
    "# Set to \"all\" for all folds, or list of fold indices [0, 1, 2, 3, 4] or [0, 2] etc.\n",
    "FOLD_SELECTION = \"all\"  # \"all\" or list like [0, 1, 2] or [3]\n",
    "\n",
    "CONFIGS = {\n",
    "    1: {\n",
    "        'name': 'Target 1: DeBERTa-large + Augmentation',\n",
    "        'epochs': 15, 'batch_size': 8, 'lr': 5e-6,\n",
    "        'use_augmentation': True, 'use_curriculum': True,\n",
    "        'focal_gamma': 2.0, 'label_smoothing': 0.1, 'r_drop_alpha': 0.0,\n",
    "        'target_accuracy': 0.85,\n",
    "        'hard_negative_topk': 2,\n",
    "        'calibrate_temperature': True,\n",
    "        'datasets': [Dataset.PDNC.value],  # Use enum value\n",
    "        'use_postprocess': False,\n",
    "        'balance_genres': False,\n",
    "        'fold_selection': FOLD_SELECTION,\n",
    "    },\n",
    "    2: {\n",
    "        'name': 'Target 2: Multi-Source + Genre Balancing',\n",
    "        'epochs': 15, 'batch_size': 8, 'lr': 2e-6,\n",
    "        'use_augmentation': True, 'use_curriculum': True,\n",
    "        'balance_genres': True, 'min_genre_acc': 0.75,\n",
    "        'target_accuracy': 0.88,\n",
    "        'hard_negative_topk': 2,\n",
    "        'calibrate_temperature': True,\n",
    "        'datasets': [Dataset.PDNC.value, Dataset.LITBANK.value, Dataset.DIRECTQUOTE.value],  # Use enum values\n",
    "        'use_postprocess': False,\n",
    "        'fold_selection': FOLD_SELECTION,\n",
    "    },\n",
    "    3: {\n",
    "        'name': 'Target 3: Ensemble + Distillation',\n",
    "        'ensemble_models': ['microsoft/deberta-v3-large', 'roberta-large'],\n",
    "        'student_model': 'microsoft/deberta-v3-base',\n",
    "        'epochs': 15, 'batch_size': 4, 'lr': 5e-6,\n",
    "        'distill_epochs': 10, 'temperature': 3.0, 'alpha': 0.7,\n",
    "        'target_accuracy': 0.90,\n",
    "        'datasets': [Dataset.PDNC.value, Dataset.LITBANK.value, Dataset.DIRECTQUOTE.value],  # Use enum values\n",
    "        'use_augmentation': True,\n",
    "        'use_curriculum': True,\n",
    "        'balance_genres': True,\n",
    "        'hard_negative_topk': 2,\n",
    "        'calibrate_temperature': True,\n",
    "        'use_postprocess': False,\n",
    "        'fold_selection': FOLD_SELECTION,\n",
    "    }\n",
    "}\n",
    "\n",
    "CONFIG = CONFIGS[TARGET_LEVEL].copy()\n",
    "\n",
    "# Validate datasets\n",
    "Dataset.validate(CONFIG.get('datasets', [Dataset.PDNC.value]))\n",
    "\n",
    "multi_source_base = f\"{REPO_DIR}/data\"\n",
    "\n",
    "CONFIG.update({\n",
    "    'base_model': 'microsoft/deberta-v3-large',\n",
    "    'max_length': 512,\n",
    "    'gradient_accumulation_steps': ENV['grad_accum'],\n",
    "    'checkpoint_every': ENV['checkpoint_every'],  # CURSOR: env-specific cadence\n",
    "    'eval_every': ENV['eval_every'],\n",
    "    'fp16': True,\n",
    "    'gradient_checkpointing': True,\n",
    "    'seed': 42,\n",
    "    'output_dir': f\"{OUTPUT_ROOT}/target_{TARGET_LEVEL}\",\n",
    "    'multi_source_base': multi_source_base,  # CURSOR: All datasets loaded via MultiSourceDataLoader\n",
    "    # CURSOR: Feature toggles (disabled by default)\n",
    "    'use_combined_loss': True,\n",
    "    'use_postprocess': True,\n",
    "    'postprocess_confidence': 0.6,\n",
    "    'use_ensemble_eval': True,\n",
    "    'ensemble_model_names': ['microsoft/deberta-v3-large'],\n",
    "    'ensemble_voting_strategy': 'weighted_average',\n",
    "    'run_cross_domain_validation': True,\n",
    "    'run_genre_adaptation': True,\n",
    "    'run_error_analysis': True,\n",
    "    'run_model_optimization': True,\n",
    "    'optimize_quantize': True,\n",
    "    'optimize_export_onnx': True,\n",
    "})\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "print(f\"Selected: {CONFIG['name']}\")\n",
    "print(f\"Target accuracy: {CONFIG['target_accuracy']:.0%}\")\n",
    "print(f\"Datasets: {CONFIG.get('datasets', [Dataset.PDNC.value])}\")\n",
    "print(f\"Output dir: {CONFIG['output_dir']}\")\n",
    "print(f\"RUN_ENV: {RUN_ENV} | checkpoint_every={CONFIG['checkpoint_every']} | grad_accum={CONFIG['gradient_accumulation_steps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "AUTO-DOWNLOAD DATASETS\n",
      "============================================================\n",
      "Datasets to download: ['pdnc']\n",
      "\n",
      "üì¶ Processing PDNC (pdnc)...\n",
      "   Description: Pride and Prejudice Dialog Novel Corpus - 22 novels, literature focus\n",
      "   Target directory: /kaggle/working/speaker-attribution-acl2023/data/pdnc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/speaker-attribution-acl2023/data/pdnc'...\n",
      "Updating files:  97% (740/762)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET DOWNLOAD COMPLETE\n",
      "============================================================\n",
      "üìö Downloaded datasets: ['pdnc']\n",
      "üìÅ Base directory: /kaggle/working/speaker-attribution-acl2023/data\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating files: 100% (762/762), done.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# AUTO-DOWNLOAD AND PREPARE ALL DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "from data.multi_source_data import download_datasets\n",
    "\n",
    "downloaded_datasets = download_datasets(\n",
    "    base_path=CONFIG[\"multi_source_base\"],\n",
    "    datasets=CONFIG.get('datasets')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detected 2 GPU(s)\n",
      "   GPU 0: Tesla T4 (14.7 GB)\n",
      "   GPU 1: Tesla T4 (14.7 GB)\n",
      "\n",
      "‚úÖ Multi-GPU training via HF Trainer (DDP)\n",
      "   Effective batch: 8 x 2 x 4 = 64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GPU SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "print(f\"üîç Detected {NUM_GPUS} GPU(s)\")\n",
    "for i in range(NUM_GPUS):\n",
    "    props = torch.cuda.get_device_properties(i)\n",
    "    print(f\"   GPU {i}: {torch.cuda.get_device_name(i)} ({props.total_memory / 1024**3:.1f} GB)\")\n",
    "\n",
    "if NUM_GPUS > 1:\n",
    "    print(f\"\\n‚úÖ Multi-GPU training via HF Trainer (DDP)\")\n",
    "    print(f\"   Effective batch: {CONFIG['batch_size']} x {NUM_GPUS} x {CONFIG['gradient_accumulation_steps']} = {CONFIG['batch_size'] * NUM_GPUS * CONFIG['gradient_accumulation_steps']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 05:03:48.434798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765343028.649424      88 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765343028.708201      88 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: 2 | FP16: True\n"
     ]
    }
   ],
   "source": [
    "import glob, random, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from data.multi_source_data import MultiSourceDataLoader\n",
    "from data.data_augmentation import QuoteAugmenter\n",
    "from data.curriculum_loader import DifficultyClassifier, CurriculumSampler, CurriculumConfig\n",
    "from evaluation.confidence_calibration import TemperatureScaling\n",
    "from models.max_performance_model import MaxPerformanceSpeakerModel\n",
    "from losses.focal_loss import CombinedLoss\n",
    "\n",
    "# CURSOR: Deterministic setup for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "print(f\"GPUs: {NUM_GPUS} | FP16: {CONFIG['fp16']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the richer model with span/mask support\n",
    "\n",
    "class QuoteDataset(Dataset):\n",
    "    def __init__(self, samples, tokenizer, max_length=512, augment=False, augmenter: QuoteAugmenter = None):\n",
    "        self.samples, self.tok, self.max_len = samples, tokenizer, max_length\n",
    "        self.augment = augment\n",
    "        self.augmenter = augmenter\n",
    "        self.par_id = self.tok.convert_tokens_to_ids(\"[PAR]\")\n",
    "        self.altq_id = self.tok.convert_tokens_to_ids(\"[ALTQUOTE]\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _maybe_augment_text(self, text: str) -> str:\n",
    "        if not self.augment or not self.augmenter:\n",
    "            return text\n",
    "        \n",
    "        # CURSOR: Multi-strategy augmentation for better generalization\n",
    "        # Apply augmentation with 50% probability (increased from 20%)\n",
    "        if random.random() > 0.5:\n",
    "            return text\n",
    "        \n",
    "        augmented = text\n",
    "        try:\n",
    "            # CURSOR: Strategy 1 - Synonym replacement (40% chance, 3-5 words)\n",
    "            if random.random() < 0.4:\n",
    "                n_synonyms = random.randint(3, 5)\n",
    "                augmented = self.augmenter.synonym_replace(augmented, protected_spans=[], n=n_synonyms)\n",
    "            \n",
    "            # CURSOR: Strategy 2 - Random word insertion (25% chance)\n",
    "            if random.random() < 0.25:\n",
    "                augmented = self.augmenter.random_insert(augmented, protected_spans=[], n=1)\n",
    "            \n",
    "            # CURSOR: Strategy 3 - Random word swap (20% chance)\n",
    "            if random.random() < 0.2:\n",
    "                augmented = self.augmenter.random_swap(augmented, protected_spans=[], n=1)\n",
    "            \n",
    "            # CURSOR: Strategy 4 - Random word deletion (15% chance, very light)\n",
    "            if random.random() < 0.15:\n",
    "                augmented = self.augmenter.random_delete(augmented, protected_spans=[], p=0.03)\n",
    "            \n",
    "            return augmented\n",
    "        except Exception:\n",
    "            return text\n",
    "\n",
    "    def _encode(self, sample):\n",
    "        base_text = self._maybe_augment_text(sample['text'])\n",
    "        base_ids = self.tok.encode(base_text, add_special_tokens=False)\n",
    "        candidates = sample['candidates']\n",
    "        cand_ids = [self.tok.encode(c, add_special_tokens=False) for c in candidates]\n",
    "\n",
    "        reserved = 1 + 1 + sum(1 + len(ci) for ci in cand_ids)\n",
    "        room = max(self.max_len - reserved, 8)\n",
    "        if len(base_ids) > room:\n",
    "            base_ids = base_ids[:room]\n",
    "\n",
    "        tokens = [self.par_id] + base_ids + [self.altq_id]\n",
    "        quote_mask = [1] * len(tokens)\n",
    "\n",
    "        # CURSOR: Track candidate start/end positions, build tokens first\n",
    "        cand_spans = []\n",
    "        for ci in cand_ids:\n",
    "            tokens.append(self.par_id)\n",
    "            start = len(tokens)\n",
    "            tokens.extend(ci)\n",
    "            end = len(tokens)\n",
    "            cand_spans.append((start, end))\n",
    "\n",
    "        if not cand_spans:\n",
    "            tokens.append(self.par_id)\n",
    "            cand_spans.append((len(tokens), len(tokens)))\n",
    "\n",
    "        # CURSOR: Create masks with uniform length (final token length)\n",
    "        final_len = len(tokens)\n",
    "        cand_masks = []\n",
    "        for start, end in cand_spans:\n",
    "            mask = [0] * final_len\n",
    "            for i in range(start, min(end, final_len)):\n",
    "                mask[i] = 1\n",
    "            cand_masks.append(mask)\n",
    "\n",
    "        # CURSOR: Extend quote_mask to match final token length (candidates added 0s)\n",
    "        if len(quote_mask) < final_len:\n",
    "            quote_mask += [0] * (final_len - len(quote_mask))\n",
    "\n",
    "        tokens = tokens[: self.max_len]\n",
    "        attention = [1] * len(tokens)\n",
    "        if len(tokens) < self.max_len:\n",
    "            pad_len = self.max_len - len(tokens)\n",
    "            tokens += [self.tok.pad_token_id] * pad_len\n",
    "            attention += [0] * pad_len\n",
    "            quote_mask += [0] * pad_len\n",
    "            cand_masks = [cm + [0] * pad_len for cm in cand_masks]\n",
    "        else:\n",
    "            quote_mask = quote_mask[: self.max_len]\n",
    "            cand_masks = [cm[: self.max_len] for cm in cand_masks]\n",
    "\n",
    "        return tokens, attention, quote_mask, cand_masks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        tokens, attention, quote_mask, cand_masks = self._encode(sample)\n",
    "        label_idx = sample['gold_index'] if sample['gold_index'] >= 0 else -100\n",
    "        return {\n",
    "            'input_ids': torch.tensor(tokens, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention, dtype=torch.long),\n",
    "            'quote_mask': torch.tensor(quote_mask, dtype=torch.long),\n",
    "            'candidate_masks': [torch.tensor(cm, dtype=torch.long) for cm in cand_masks],\n",
    "            'label_idx': torch.tensor(label_idx, dtype=torch.long),\n",
    "            'quote_id': sample['quote_id']\n",
    "        }\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.gamma, self.ls = gamma, label_smoothing\n",
    "    def forward(self, inputs, targets):\n",
    "        smoothed = targets.float() * (1 - self.ls) + 0.5 * self.ls\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        ce = F.binary_cross_entropy(probs, smoothed, reduction='none')\n",
    "        pt = torch.where(targets > 0, probs, 1 - probs).clamp(min=1e-6, max=1-1e-6)\n",
    "        return ((1 - pt) ** self.gamma * ce).mean()\n",
    "\n",
    "\n",
    "# Data helpers\n",
    "\n",
    "def _add_hard_negatives(samples, topk):\n",
    "    \"\"\"Add hard negative candidates from frequent speakers across the dataset.\"\"\"\n",
    "    if not topk or not samples:\n",
    "        return samples\n",
    "    freq = {}\n",
    "    for s in samples:\n",
    "        for c in s['candidates']:\n",
    "            freq[c] = freq.get(c, 0) + 1\n",
    "    sorted_cands = [c for c, _ in sorted(freq.items(), key=lambda x: -x[1])]\n",
    "    for s in samples:\n",
    "        existing = set(s['candidates'])\n",
    "        extras = [c for c in sorted_cands if c not in existing and c != s['gold']][:topk]\n",
    "        s['candidates'] = s['candidates'] + extras\n",
    "    return samples\n",
    "\n",
    "\n",
    "def _convert_multi_source_sample(s, idx, source='unknown'):\n",
    "    \"\"\"Convert MultiSourceDataLoader sample format to QuoteDataset format.\"\"\"\n",
    "    gold = s.get('speaker', '')\n",
    "    text = s.get('text') or s.get('quote') or ''\n",
    "    source = s.get('source', source)\n",
    "    genre = s.get('genre', source)\n",
    "    book_id = s.get('book_id', '')\n",
    "    \n",
    "    if not gold or not text:\n",
    "        return None\n",
    "    \n",
    "    qid = f\"{source}:{book_id}:{idx}\" if book_id else f\"{source}:{idx}\"\n",
    "    return {\n",
    "        'quote_id': qid,\n",
    "        'text': text,\n",
    "        'candidates': [gold],\n",
    "        'gold': gold,\n",
    "        'genre': genre,\n",
    "        'source': source,\n",
    "        'book_id': book_id\n",
    "    }\n",
    "\n",
    "\n",
    "def load_pdnc_data_via_multi_source(base_path: str, n_folds: int = 5, seed: int = 42):\n",
    "    \"\"\"\n",
    "    Load PDNC data using MultiSourceDataLoader and create k-fold splits by book.\n",
    "    \n",
    "    Returns:\n",
    "        List of (train, val, test) tuples for each fold\n",
    "    \"\"\"\n",
    "    loader = MultiSourceDataLoader(base_path=base_path, datasets=['pdnc'], seed=seed)\n",
    "    loader.load_all()\n",
    "    \n",
    "    all_samples = []\n",
    "    for genre_samples in loader.data_by_genre.values():\n",
    "        all_samples.extend(genre_samples)\n",
    "    \n",
    "    if not all_samples:\n",
    "        print(\"‚ö†Ô∏è No PDNC samples loaded via MultiSourceDataLoader\")\n",
    "        return []\n",
    "    \n",
    "    # CURSOR: Group samples by book_id for leave-book-out cross-validation\n",
    "    by_book = defaultdict(list)\n",
    "    for i, s in enumerate(all_samples):\n",
    "        book_id = s.get('book_id', 'unknown')\n",
    "        by_book[book_id].append((i, s))\n",
    "    \n",
    "    book_ids = sorted(by_book.keys())\n",
    "    n_books = len(book_ids)\n",
    "    \n",
    "    if n_books < n_folds:\n",
    "        print(f\"‚ö†Ô∏è Only {n_books} books, adjusting to {n_books} folds\")\n",
    "        n_folds = max(1, n_books)\n",
    "    \n",
    "    # CURSOR: Assign books to folds for leave-x-out cross-validation\n",
    "    random.seed(seed)\n",
    "    shuffled_books = book_ids.copy()\n",
    "    random.shuffle(shuffled_books)\n",
    "    \n",
    "    fold_book_assignments = [[] for _ in range(n_folds)]\n",
    "    for i, book_id in enumerate(shuffled_books):\n",
    "        fold_book_assignments[i % n_folds].append(book_id)\n",
    "    \n",
    "    folds_data = []\n",
    "    for fold_idx in range(n_folds):\n",
    "        test_books = set(fold_book_assignments[fold_idx])\n",
    "        val_books = set(fold_book_assignments[(fold_idx + 1) % n_folds])\n",
    "        train_books = set(shuffled_books) - test_books - val_books\n",
    "        \n",
    "        train_samples, val_samples, test_samples = [], [], []\n",
    "        \n",
    "        for book_id, samples_list in by_book.items():\n",
    "            for i, s in samples_list:\n",
    "                converted = _convert_multi_source_sample(s, i, 'pdnc')\n",
    "                if converted is None:\n",
    "                    continue\n",
    "                if book_id in test_books:\n",
    "                    test_samples.append(converted)\n",
    "                elif book_id in val_books:\n",
    "                    val_samples.append(converted)\n",
    "                else:\n",
    "                    train_samples.append(converted)\n",
    "        \n",
    "        folds_data.append((train_samples, val_samples, test_samples))\n",
    "    \n",
    "    return folds_data\n",
    "\n",
    "\n",
    "def load_datasets(base_path: str, datasets: list):\n",
    "    \"\"\"\n",
    "    Load datasets using MultiSourceDataLoader and convert to training format.\n",
    "    Works for single or multiple datasets. Uses unified sample conversion.\n",
    "    \"\"\"\n",
    "    loader = MultiSourceDataLoader(base_path=base_path, datasets=datasets, seed=CONFIG['seed'])\n",
    "    loader.load_all()\n",
    "    \n",
    "    # Use the proper split_by_genre method from the module\n",
    "    train_samples, val_samples, test_samples = loader.split_by_genre(\n",
    "        val_ratio=0.1,\n",
    "        test_ratio=0.1\n",
    "    )\n",
    "    \n",
    "    # CURSOR: Convert using unified helper function\n",
    "    train_converted = [_convert_multi_source_sample(s, i) for i, s in enumerate(train_samples)]\n",
    "    train_converted = [s for s in train_converted if s is not None]\n",
    "    \n",
    "    val_converted = [_convert_multi_source_sample(s, i) for i, s in enumerate(val_samples)]\n",
    "    val_converted = [s for s in val_converted if s is not None]\n",
    "    \n",
    "    test_converted = [_convert_multi_source_sample(s, i) for i, s in enumerate(test_samples)]\n",
    "    test_converted = [s for s in test_converted if s is not None]\n",
    "    \n",
    "    # Add hard negatives\n",
    "    train_converted = _add_hard_negatives(train_converted, CONFIG.get('hard_negative_topk', 0))\n",
    "    val_converted = _add_hard_negatives(val_converted, CONFIG.get('hard_negative_topk', 0))\n",
    "    test_converted = _add_hard_negatives(test_converted, CONFIG.get('hard_negative_topk', 0))\n",
    "    \n",
    "    # Update gold_index after adding hard negatives\n",
    "    for s in train_converted + val_converted + test_converted:\n",
    "        s['gold_index'] = s['candidates'].index(s['gold']) if s['gold'] in s['candidates'] else -1\n",
    "    \n",
    "    return train_converted, val_converted, test_converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã PDNC Folds to train: [0, 1, 2, 3, 4]\n",
      "üìÇ Loading PDNC data via MultiSourceDataLoader...\n",
      "\n",
      "üìÇ Loading PDNC from /kaggle/working/speaker-attribution-acl2023/data/pdnc...\n",
      "  Found PDNC training data at /kaggle/working/speaker-attribution-acl2023/data/pdnc/training/data/pdnc\n",
      "  Found 15 quote files in leave-x-out splits\n",
      "  Processing: quotes.dev.txt (4223 lines)\n",
      "    First line preview: AgeOfInnocence\tQ1-0\tCHAR_35\t52\t[[18, 19, 1, \"CHAR_35\"], [92, 94, 0, \"CHAR_15\"]]\tglance flitting back to the young girl w...\n",
      "  Loaded 161542 samples, parse_errors=16788\n",
      "   ‚úÖ Loaded 161,542 samples from PDNC\n",
      "   ‚úÖ Created 5 folds from PDNC data\n",
      "\n",
      "üìä Preview - Fold 0 stats (before hard negatives):\n",
      "   Train quotes: 89705\n",
      "   Val quotes: 29085\n",
      "   Test quotes: 42752\n",
      "\n",
      "üîÑ Will train 5 fold(s): [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "datasets_to_load = CONFIG.get('datasets', ['pdnc'])\n",
    "# CURSOR: Use PDNC folds when pdnc is in datasets (via MultiSourceDataLoader)\n",
    "use_pdnc_folds = 'pdnc' in datasets_to_load\n",
    "other_datasets = [d for d in datasets_to_load if d != 'pdnc']\n",
    "\n",
    "if use_pdnc_folds:\n",
    "    fold_selection = CONFIG.get('fold_selection', [0])\n",
    "\n",
    "    if fold_selection == \"all\":\n",
    "        FOLDS_TO_TRAIN = list(range(5))\n",
    "    elif isinstance(fold_selection, list):\n",
    "        FOLDS_TO_TRAIN = fold_selection\n",
    "    else:\n",
    "        FOLDS_TO_TRAIN = [int(fold_selection)]\n",
    "\n",
    "    print(f\"üìã PDNC Folds to train: {FOLDS_TO_TRAIN}\")\n",
    "else:\n",
    "    FOLDS_TO_TRAIN = [0]  # Single iteration for multi-dataset\n",
    "    print(f\"üìã Training with datasets: {datasets_to_load}\")\n",
    "\n",
    "# CURSOR: Pre-load all PDNC folds via MultiSourceDataLoader (unified approach)\n",
    "pdnc_folds_data = None\n",
    "if use_pdnc_folds:\n",
    "    print(f\"üìÇ Loading PDNC data via MultiSourceDataLoader...\")\n",
    "    pdnc_folds_data = load_pdnc_data_via_multi_source(\n",
    "        base_path=CONFIG['multi_source_base'],\n",
    "        n_folds=5,\n",
    "        seed=CONFIG['seed']\n",
    "    )\n",
    "    if pdnc_folds_data:\n",
    "        print(f\"   ‚úÖ Created {len(pdnc_folds_data)} folds from PDNC data\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Failed to load PDNC folds, falling back to load_datasets\")\n",
    "        use_pdnc_folds = False\n",
    "\n",
    "def load_pdnc_fold(fold_idx: int):\n",
    "    \"\"\"Load train/val/test data for a specific PDNC fold via MultiSourceDataLoader.\"\"\"\n",
    "    if pdnc_folds_data is None or fold_idx >= len(pdnc_folds_data):\n",
    "        print(f\"   ‚ö†Ô∏è Fold {fold_idx} not available, using load_datasets fallback\")\n",
    "        return load_datasets(CONFIG['multi_source_base'], ['pdnc'])\n",
    "    \n",
    "    train_data, val_data, test_data = pdnc_folds_data[fold_idx]\n",
    "    \n",
    "    # CURSOR: Add hard negatives and gold_index\n",
    "    train_data = _add_hard_negatives(train_data, CONFIG.get('hard_negative_topk', 0))\n",
    "    val_data = _add_hard_negatives(val_data, CONFIG.get('hard_negative_topk', 0))\n",
    "    test_data = _add_hard_negatives(test_data, CONFIG.get('hard_negative_topk', 0))\n",
    "    \n",
    "    for s in train_data + val_data + test_data:\n",
    "        s['gold_index'] = s['candidates'].index(s['gold']) if s['gold'] in s['candidates'] else -1\n",
    "    \n",
    "    # CURSOR: Combine with other datasets if any\n",
    "    if other_datasets:\n",
    "        print(f\"   + Adding datasets: {other_datasets}\")\n",
    "        other_train, other_val, other_test = load_datasets(CONFIG['multi_source_base'], other_datasets)\n",
    "        train_data = train_data + other_train\n",
    "        val_data = val_data + other_val\n",
    "        test_data = test_data + other_test\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# CURSOR: Data loading is now handled inside the training loop for multi-fold support\n",
    "# Preview first fold stats only\n",
    "if use_pdnc_folds and pdnc_folds_data:\n",
    "    preview_train, preview_val, preview_test = pdnc_folds_data[FOLDS_TO_TRAIN[0]]\n",
    "    print(f\"\\nüìä Preview - Fold {FOLDS_TO_TRAIN[0]} stats (before hard negatives):\")\n",
    "    print(f\"   Train quotes: {len(preview_train)}\")\n",
    "    print(f\"   Val quotes: {len(preview_val)}\")\n",
    "    print(f\"   Test quotes: {len(preview_test)}\")\n",
    "    print(f\"\\nüîÑ Will train {len(FOLDS_TO_TRAIN)} fold(s): {FOLDS_TO_TRAIN}\")\n",
    "else:\n",
    "    print(f\"üìÇ Will load datasets: {datasets_to_load}\")\n",
    "    print(f\"üîÑ Single training run (no cross-validation folds)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/quote-attribution-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAINING SETUP AND HELPERS\n",
    "# =============================================================================\n",
    "\n",
    "# CURSOR: Disable gradient checkpointing for multi-GPU (causes backward graph conflicts)\n",
    "USE_GRADIENT_CHECKPOINTING = NUM_GPUS == 1 and CONFIG.get('gradient_checkpointing', False)\n",
    "print(f\"‚öôÔ∏è Gradient checkpointing: {USE_GRADIENT_CHECKPOINTING} (disabled for multi-GPU)\")\n",
    "\n",
    "# CURSOR: Collate function for variable-length candidate masks\n",
    "def collate_fn(batch):\n",
    "    max_cands = max(len(item['candidate_masks']) for item in batch)\n",
    "    input_ids = torch.stack([b['input_ids'] for b in batch])\n",
    "    attention_mask = torch.stack([b['attention_mask'] for b in batch])\n",
    "    quote_mask = torch.stack([b['quote_mask'] for b in batch])\n",
    "    cand_masks, cand_attn = [], []\n",
    "    for b in batch:\n",
    "        masks = b['candidate_masks']\n",
    "        orig_len = len(masks) or 1\n",
    "        if not masks:\n",
    "            masks = [torch.zeros_like(b['input_ids'])]\n",
    "        pad_count = max_cands - orig_len\n",
    "        if pad_count > 0:\n",
    "            masks = masks + [torch.zeros_like(masks[0])] * pad_count\n",
    "        cand_masks.append(torch.stack(masks))\n",
    "        cand_attn.append(torch.tensor([1] * orig_len + [0] * pad_count, dtype=torch.long))\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'quote_mask': quote_mask,\n",
    "        'candidate_masks': torch.stack(cand_masks),\n",
    "        'candidate_attention_mask': torch.stack(cand_attn),\n",
    "        'labels': torch.stack([b['label_idx'] for b in batch]),\n",
    "    }\n",
    "\n",
    "# CURSOR: Simple label smoothing cross entropy (stable with gradient checkpointing)\n",
    "class LabelSmoothingCE(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.ignore_index = ignore_index\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        # CURSOR: Mask out ignored indices\n",
    "        mask = targets != self.ignore_index\n",
    "        if not mask.any():\n",
    "            return torch.tensor(0.0, device=logits.device, requires_grad=True)\n",
    "        \n",
    "        logits = logits[mask]\n",
    "        targets = targets[mask]\n",
    "        \n",
    "        n_classes = logits.size(-1)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        # CURSOR: Create smoothed targets\n",
    "        with torch.no_grad():\n",
    "            smooth_targets = torch.full_like(log_probs, self.smoothing / (n_classes - 1))\n",
    "            smooth_targets.scatter_(1, targets.unsqueeze(1), 1 - self.smoothing)\n",
    "        \n",
    "        loss = -(smooth_targets * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "\n",
    "# CURSOR: Custom Trainer for our model\n",
    "class QuoteAttributionTrainer(Trainer):\n",
    "    \"\"\"Custom trainer that handles our model's unique input format.\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.custom_loss_fn = loss_fn\n",
    "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop('labels')\n",
    "        logits, _ = model(\n",
    "            inputs['input_ids'],\n",
    "            inputs['attention_mask'],\n",
    "            inputs['quote_mask'],\n",
    "            inputs['candidate_masks'],\n",
    "            inputs['candidate_attention_mask']\n",
    "        )\n",
    "        if inputs['candidate_attention_mask'] is not None:\n",
    "            logits = logits.masked_fill(inputs['candidate_attention_mask'] == 0, -1e9)\n",
    "        \n",
    "        if self.custom_loss_fn is not None:\n",
    "            loss = self.custom_loss_fn(logits, labels)\n",
    "        else:\n",
    "            loss = self.ce_loss(logits, labels)\n",
    "        \n",
    "        return (loss, {'logits': logits}) if return_outputs else loss\n",
    "\n",
    "# CURSOR: Metrics function\n",
    "def compute_metrics(eval_pred: EvalPrediction) -> Dict[str, float]:\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    mask = labels >= 0\n",
    "    acc = (preds[mask] == labels[mask]).mean()\n",
    "    return {'accuracy': float(acc)}\n",
    "\n",
    "# CURSOR: Loss function - use simple label smoothing CE for stability\n",
    "def get_loss_fn():\n",
    "    smoothing = CONFIG.get('label_smoothing', 0.1)\n",
    "    if smoothing > 0:\n",
    "        return LabelSmoothingCE(smoothing=smoothing)\n",
    "    return None\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "print(\"‚úÖ Training helpers ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MULTI-FOLD TRAINING LOOP\n",
    "# =============================================================================\n",
    "# CURSOR: Trains all selected folds sequentially\n",
    "# Each fold gets fresh model weights for proper cross-validation\n",
    "# Models are saved per-fold for ensemble inference\n",
    "\n",
    "import gc\n",
    "\n",
    "# CURSOR: Track results across all folds\n",
    "fold_results = {}\n",
    "all_fold_accuracies = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"üöÄ MULTI-FOLD TRAINING: {CONFIG['name']}\")\n",
    "print(f\"   Folds to train: {FOLDS_TO_TRAIN}\")\n",
    "print(f\"   GPUs: {NUM_GPUS} | Batch/GPU: {CONFIG['batch_size']}\")\n",
    "print(f\"   Effective batch: {CONFIG['batch_size'] * NUM_GPUS * CONFIG['gradient_accumulation_steps']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for fold_idx in FOLDS_TO_TRAIN:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÇ FOLD {fold_idx + 1}/{len(FOLDS_TO_TRAIN)} (index={fold_idx})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # CURSOR: Load data for this fold\n",
    "    if use_pdnc_folds:\n",
    "        print(f\"   Loading PDNC fold {fold_idx}...\")\n",
    "        train_samples, val_samples, test_samples = load_pdnc_fold(fold_idx)\n",
    "    else:\n",
    "        print(f\"   Loading datasets: {datasets_to_load}...\")\n",
    "        train_samples, val_samples, test_samples = load_datasets(CONFIG['multi_source_base'], datasets_to_load)\n",
    "    \n",
    "    print(f\"   Train: {len(train_samples)} | Val: {len(val_samples)} | Test: {len(test_samples)}\")\n",
    "    \n",
    "    # CURSOR: Create fresh model for each fold (important for proper cross-validation)\n",
    "    print(f\"   Initializing fresh model...\")\n",
    "    set_seed(CONFIG['seed'] + fold_idx)  # Different seed per fold for diversity\n",
    "    model = MaxPerformanceSpeakerModel(CONFIG.get('base_model', 'microsoft/deberta-v3-large'))\n",
    "    if USE_GRADIENT_CHECKPOINTING:\n",
    "        model.encoder.gradient_checkpointing_enable()\n",
    "    tokenizer = model.get_tokenizer()\n",
    "    \n",
    "    # CURSOR: Create augmenter\n",
    "    augmenter = QuoteAugmenter(seed=CONFIG['seed'] + fold_idx) if CONFIG.get('use_augmentation', False) else None\n",
    "    \n",
    "    # CURSOR: Apply curriculum sorting if enabled\n",
    "    if CONFIG.get('use_curriculum', False):\n",
    "        train_samples = sorted(train_samples, key=lambda s: len(s['text']))\n",
    "    \n",
    "    # CURSOR: Create datasets\n",
    "    train_dataset = QuoteDataset(\n",
    "        train_samples, tokenizer, CONFIG['max_length'],\n",
    "        augment=CONFIG.get('use_augmentation', False), augmenter=augmenter\n",
    "    )\n",
    "    val_dataset = QuoteDataset(val_samples, tokenizer, CONFIG['max_length'])\n",
    "    \n",
    "    # CURSOR: Fold-specific output directory\n",
    "    fold_output_dir = f\"{CONFIG['output_dir']}/fold_{fold_idx}\"\n",
    "    os.makedirs(fold_output_dir, exist_ok=True)\n",
    "    \n",
    "    # CURSOR: Reduce batch size for multi-GPU without gradient checkpointing\n",
    "    # DeBERTa-large needs ~6GB per sample, T4 has 15GB, so batch=2 is safe\n",
    "    effective_batch = 2 if not USE_GRADIENT_CHECKPOINTING else CONFIG['batch_size']\n",
    "    # CURSOR: Increase grad accum to maintain effective batch size\n",
    "    effective_grad_accum = CONFIG['gradient_accumulation_steps'] * (CONFIG['batch_size'] // effective_batch)\n",
    "    print(f\"   Batch/GPU: {effective_batch} | Grad accum: {effective_grad_accum} | Effective: {effective_batch * NUM_GPUS * effective_grad_accum}\")\n",
    "    \n",
    "    # CURSOR: Training arguments for this fold\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=fold_output_dir,\n",
    "        num_train_epochs=CONFIG['epochs'],\n",
    "        per_device_train_batch_size=effective_batch,\n",
    "        per_device_eval_batch_size=effective_batch,\n",
    "        gradient_accumulation_steps=effective_grad_accum,\n",
    "        learning_rate=CONFIG['lr'],\n",
    "        weight_decay=0.01,\n",
    "        fp16=CONFIG['fp16'],\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        \n",
    "        # Evaluation and saving\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=CONFIG['eval_every'],\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=CONFIG['checkpoint_every'],\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        \n",
    "        # Logging\n",
    "        logging_steps=100,\n",
    "        logging_first_step=True,\n",
    "        report_to=\"none\",\n",
    "        \n",
    "        # Performance - use 0 workers for multi-GPU stability\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_pin_memory=True,\n",
    "        remove_unused_columns=False,\n",
    "        \n",
    "        # Seed\n",
    "        seed=CONFIG['seed'] + fold_idx,\n",
    "    )\n",
    "    \n",
    "    # CURSOR: Create trainer for this fold\n",
    "    trainer = QuoteAttributionTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "        loss_fn=get_loss_fn(),\n",
    "    )\n",
    "    \n",
    "    # CURSOR: Train this fold\n",
    "    print(f\"\\n   üèãÔ∏è Training fold {fold_idx}...\")\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # CURSOR: Evaluate on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    fold_accuracy = eval_results.get('eval_accuracy', 0.0)\n",
    "    all_fold_accuracies.append(fold_accuracy)\n",
    "    \n",
    "    # CURSOR: Save best model for this fold\n",
    "    best_model_path = f\"{fold_output_dir}/best_model\"\n",
    "    trainer.save_model(best_model_path)\n",
    "    \n",
    "    # CURSOR: Store results\n",
    "    fold_results[fold_idx] = {\n",
    "        'accuracy': fold_accuracy,\n",
    "        'train_loss': train_result.training_loss,\n",
    "        'model_path': best_model_path,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ Fold {fold_idx} complete!\")\n",
    "    print(f\"      Accuracy: {fold_accuracy:.4f}\")\n",
    "    print(f\"      Model saved: {best_model_path}\")\n",
    "    \n",
    "    # CURSOR: Clean up GPU memory before next fold\n",
    "    del model, trainer, train_dataset, val_dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üèÜ MULTI-FOLD TRAINING COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nüìä Results per fold:\")\n",
    "for fold_idx, results in fold_results.items():\n",
    "    print(f\"   Fold {fold_idx}: Accuracy = {results['accuracy']:.4f}\")\n",
    "\n",
    "if len(all_fold_accuracies) > 1:\n",
    "    mean_acc = np.mean(all_fold_accuracies)\n",
    "    std_acc = np.std(all_fold_accuracies)\n",
    "    print(f\"\\nüìà Cross-validation summary:\")\n",
    "    print(f\"   Mean accuracy: {mean_acc:.4f} ¬± {std_acc:.4f}\")\n",
    "    print(f\"   Min: {min(all_fold_accuracies):.4f} | Max: {max(all_fold_accuracies):.4f}\")\n",
    "else:\n",
    "    print(f\"\\nüìà Single fold accuracy: {all_fold_accuracies[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Models saved to: {CONFIG['output_dir']}/fold_*/best_model\")\n",
    "print(f\"{'='*70}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
